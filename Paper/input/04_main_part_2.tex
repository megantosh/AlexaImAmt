\chapter{Skill Implementation}%: \inote{Kosten-/Terminabfrage}}
\label{maintwo}

In this chapter we present our implementation and hands-on experience throughout.
The code is available on \inote{github, the new amazon account? ...}
There are many ways to perform a setup, several languages we can use to programme 
our Skill and throughout the development process some of these steps were changed. We present the most recent interfaces and implementation possibility using Node.js on AWS Lambda, However, this is very likely to change in a near future.

\section{Setup}


\todo{codechunks different labeling??
}

\subsection*{Minimum Requirements}
\begin{itemize}
	\item[Amazon Account] We use it in conjunction with AWS and the Alexa Developer Console \footnote{create one from anywhere on the Amazon Website, e.g. here \url{https://aws.amazon.com/de/resources/create-account/}} as well as to test our skill. Once we activate our account on the developer console, the skills we develop become automatically reachable on any Alexa-enabled device linked to our account (as an end-user).
	
	\item[Command Line] - \textbf{Python 3} or\textbf{ Ruby 4} need to be installed as a foundation for ASK CLI and AWS CLI.\\
	- A package manager such as Pip Installs Packages (\textbf{PIP}) for Python or \textbf{RubyGems} for Ruby.\\
	- Depending on OS, further packages and package managers might need to be installed, e.g. Command-Line Tools for Xcode and Homebrew on the Mac. This will be prompted throughout the installation.
	\inote{brew, easyinstall python / win}
	
	
	\item[API] Our endpoint provides us with JSON responses to the queries we do through a RESTful interface from within our Lambda function (back-end code) \footnote{rechable on:\url{https://newsreel-edu.aot.tu-berlin.de/solr}}.
	
	\item[Audio] An encoder to create 48kpbs constant bitrate MP3-Format. ffmpeg\footnote{convert by running \lstinline|$ ffmpeg -i <inFile> -ac 2 -codec:a libmp3lame -b:a 48k -ar 16000 <outFile.mp3>|} or Audacity \footnote{\url{http://www.audacityteam.org/}} can be used to convert to an Alexa-friendly file format like in the \textsc{ASK Documentation}\footnote{\url{https://developer.amazon.com/de/docs/custom-skills/speech-synthesis-markup-language-ssml-reference.html\#h3_converting_mp3}}.
	
\end{itemize}


\subsection*{Creating AWS Credentials}

With the Amazon account we just created (or already have), we will proceed with extending it to become a developer account. As we move within the free tier of AWS, no charges were applied. However, a credit card might be required for eventual future billings if the tier limitations were exceeded. We mention pricing schemes in Section \ref{choiceOfPlatform} \footnote{More information on pricing available on: \url{https://aws.amazon.com/de/pricing/}}. 

\subsubsection*{Generating Access Keys}~\label{accesskeys}
Linking happens through a private and public key pair - the \textbf{access key}.
Combination of an \textit{access key ID} (like \lstinline|AK..7EXAMPLE|) and a \textit{secret access key} (e.g \lstinline|{wJalrXUt..I/K7..G/bPx..YEXAMPLEKEY|). We use access keys to sign API requests that you make to AWS.

Creating Access Keys is described in the \textsc{AWS Documentation}\footnote{\url{https://docs.aws.amazon.com/general/latest/gr/managing-aws-access-keys.html}}


\subsection*{Initialising The Development Environment}

As minimum package requirements can vary a lot between one OS and another, using a virtual machine is suggested for teams. AWS offers Elastic Compute Cloud (EC2) as a service for virtual machines in the cloud. Although this step is mainly for performing command-line prompts later on, if opting for that, it is convenient to avail a web browser inside the virtual machine instance. Otherwise for browser communication the tool we are going to use will generate links that we would need to copy and paste into a browser outside of the virtual machine to link it with the Amazon account we use.


\subsection*{Installing Command-Line Tools}

\begin{minted}[linenos,tabsize=2, bgcolor=bgkolor, breaklines, fontsize=\footnotesize]{bash}
	$ which node			#check if installed
	$ which npm			 #check if installed
	$ which python		#check if installed
	$ which ruby			#check if installed if proceeding with rbenv
	$ python --version #we use 3.5.3
	$ node --version	 #we use 7.3.0
	$ npm --version 	 #we use 4.1.1
	$ pip install aws-cli #Amazon Web Services Command Line Interface
	$ aws --version		#check successful installation. We use aws-cli/1.15.1 Python/3.5.2 Darwin/15.6.0 botocore/1.10.1
	$ npm install ask-cli| #Alexa Skills Cit Command Line Interface
	$ ask --version	  #we use 1.1.6
\end{minted}




%\begin{minted}[linenos,tabsize=2,breaklines]{bash}




\subsection*{Understanding the API Query parameters}
HTTP(S) endpoint:
\url{http://newsreel-edu.aot.tu-berlin.de/solr/#/d115}

Rest Query
Solr Syntax (only url. he knows solr better than i do)








step by step code analysis

\url{https://github.com/alexa/alexa-skills-kit-sdk-for-nodejs/blob/master/Readme.md}




%\subsection*{requirements}

for audio (old)

json format https://stackoverflow.com/questions/41776014/how-to-correctly-specify-ssml-in-an-alexa-skill-lambda-function





references:

\url{https://developer.amazon.com/docs/custom-skills/speech-synthesis-markup-language-ssml-reference.html#audio}



blogs:
\url{https://developer.amazon.com/post/Tx3FXYSTHS579WO/Announcing-New-Alexa-Skills-Kit-ASK-Features-SSML-Audio-Tags-and-Developer-Porta}

With the JSON we have, we try to maximise its use, but we need to consider that with starting a Skill, it is better to start from scratch sometimes and as we go, we see what is the relevant information that we can integrate into our Skill.

We analyze the output of the \textsc{Virtual Citizen Assistant } and realize it makes less sense to start with that, so we refer to the underlying endpoint. Since this is the Solr Server that delivers JSON objects and is more realistic to maneuver, we analyse the queries we can get from there. and try to fit it into our interaction model.

Then we move on to the interaction model. On paper, we draft the use-cases to determine what are our intents first to group these into fewer intents than the services we have. Given that there are many public services related to a similar case, we design our Skill to make it possible to group them into less intents. The advantage of this is that it allows us to at least have fewer 'ServiceIntents' than the ever growing number of services, which means that we want to also be able to track new services as they get inserted into the catalogue to be able to either map them to old intents by extending these, or to introduce new intents if this does not work.



\todo{ moved from intro\\


our now more than \inote{4}
scenarios:
\begin{itemize}
	\item a general scenario of predefined categories related to any service \tocite{hier schon erwähnen? \inote{(prerequisites, costs, documents, ...)}}
	\item special application on \textbf{Residence Registration} - ``Anmeldung einer Wohnung''
	\item special application on \textbf{Applying for a Residence Permit} - mutliple services related to ``Aufenthaltstitel''
	\item ``car registration'' -  special application on \textbf{Car Registration''} - multiple services  related to ``Kraftfahrzeug (KFZ)''
	%	\item[scenario 4] \inote{yet to be decided or if to implement}
\end{itemize}}

%%%%%%%%%%%%%%%



\todo{moved from AWS Micro-services list\\

	We might as well use just our own, any other privately or cloud-based server solution to host our code and use it as an endpoint for our software, however choosing Lambda takes away the overhead of linking the front-end with the back-end of the Skill %program we develop (an Alexa Skill as we describe below). 

}

%%%%%%%%%%%






%\section{step-by-step}

start with interaction model
then use builder
then fulfill functions


steps to git commit
deploy
clone
change in browser
change offline


if u use a browser, remember to keep the session active otherwise your model might get lost in the POST

%\section{Code Analysis}
\section[Features]{Feature Implementations}


\subsection{Creating SSML and Audio}


\url{https://developer.amazon.com/docs/custom-skills/speech-synthesis-markup-language-ssml-reference.html#audio}



\subsection{Checking the Next available appointment}

Although this is a proof of concept, with an API extension from ITDZ's side, it is equally easy to implement a feature to look up next available appointments.
The actual booking would require Alexa to send POST requests and persistently retain these on the API's side with the option to impement another feature to save the same appointment to the calendar linked to the Amazon account used with this Alexa instance. This might require account linking, too, if we need to pass the appointment data through the Skill to an online personal calendar endpoint, bypassing Alexa itself.

Booking an appointment happens for now only through Berlin.de's website by starting at either \href{https://service.berlin.de/terminvereinbarung/termin/}{the appointment booking page} \footnote{\url{https://service.berlin.de/terminvereinbarung/termin/}} which links to the actual booking pages via choosing the service or the location where the service 



\section{Code Analysis}

from \url{https://github.com/alexa/alexa-skills-kit-sdk-for-nodejs/blob/master/Readme.md}
The difference between :ask/listen and :tell/speak is that after a :tell/speak action, the session is ended without waiting for the user to provide more input. We will compare the two ways using response or using responseBuilder to create the response object in next section.




jsons sent/received in appendix
\ref{jsonFromAlexa}






legal things like the EU-partner rule.
eu rules override local
bas u cant explain it to people 3ashan they have to be give the choice.
el mawdou3 mo3aqqad but codified here
\url{https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:02004L0038-20110616}









\section{Testing}

continuous testing during development, noch nicht evaulation, although the same techniques are pretty much used afterwards. Requires 10 users a day to generate

\todo{history API - Dave isbitzkis tweet}
\mintinline{bash}{$ ask api intent-requests-history <-s|--skill-id <skillId>> [--filters <value>] [--max-results <value>] [--sort-direction <value>] [--sort-field <value>] [--next-token <value>]}



\url{https://developer.amazon.com/docs/smapi/ask-cli-command-reference.html#intent-requests-history-subcommand}


https://developer.amazon.com/docs/smapi/intent-request-history.html


\section{Deployment}

\section{Approval and Publishing}
\label{approval}
	Continuous Skill Approval is the process of Amazon deciding whether each uploaded version / update is still fit for purpose, make the skill better or worse in conjunction with other skills on the Store % or change things to worse partly
	
	\todo{mention that 3ashan homa store w keda fal mawdou3 lazem yekoun mo7kam w 7agat homa bey7ebouha and the reasons why things could get rejected according to their policy and some scenarios}

\section{Debugging / Troubleshooting}

\todo{API TLS certificate. No base64
	just \mintinline{javascript}{rejectUnauthorized: false}
	
}


\section{Documentation Updates}
https://www.gitbook.com/join/tu-berlin/-LAZYgGmoeaEZGb8cYg2
https://tu-berlin.gitbook.io/alexa/

% Implementation as Facebook Messenger Bot / Google Action
\textcolor{magenta}{
- as an example for text\\
- implementing the answer suggestions as buttons\\
- passing data to the Bürgeramt terminseite\\
https://console.dialogflow.com/api-client/ \\
https://console.actions.google.com
}


%Solr is not secure (ein kleines thing in future work)
Solr has to be secure
\url{https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteEndpoints.html#WebsiteRestEndpointDiff}


Hey:

do this set up as prerequisites first
as a deployment script

- install aws cli
- install ask cli
- set up a profile on AWS
- ask init etc.

https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html

There is no AWS credential setup yet, do you want to continue the initialization?

https://developer.amazon.com/docs/smapi/quick-start-alexa-skills-kit-command-line-interface.html



























Manage IAM roles (User, groups, rights, policies etc.)


all logs go onto cloudwatch
including when the request is not right etc...can be helpful to know what users want, beyond testing





amazon does not disclose avaliable values for their slot types (lists), but they give you examples here
%https://developer.amazon.com/docs/custom-skills/slot-type-reference.html#h2_extend_types


===

finally, we had to resolve to the information publicly available to tailor custom scenarios



 ===
once you upload the new lambda, the old one is gone, unless you version it like this:
https://docs.aws.amazon.com/lambda/latest/dg/versioning-aliases.html



====

first i got screwed over with this Big nerd ranch then this happened: alexa-skill module
- so don't use this tutorial, although very helpful for a beginner and makes you understand what happens under the hood, it has been abstracted in many other function and the logic is no longer the same. - which explains why no one starred it

https://github.com/matt-kruse/alexa-app

https://www.bignerdranch.com/blog/developing-alexa-skills-locally-with-nodejs-deploying-your-skill-to-staging/



\todo{
	OnLaunch\\
	IntentHandler\\
	intent is triggered by utterence\\
	account verlinkungen etc\\
}

Prob with outdated tutorials

\todo{
eventually mention here: \\
as we mentioned Amazon's strong take on constant changes, we will go over the workarounds and circumventions to retain a working version of the Skill we present, discuss the downside of adaptability to these changes \inote{(constantly basastem nafsi 3ala 7aga gedida)}
}